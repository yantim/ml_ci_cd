#!/bin/bash

# ML CI/CD Pipeline Demo Script
# This script demonstrates the complete MLOps pipeline

set -e  # Exit on any error

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

# Function to print colored output
print_status() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

print_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

print_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

print_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

print_header() {
    echo -e "\n${PURPLE}$1${NC}"
    echo -e "${PURPLE}$(printf '=%.0s' {1..50})${NC}\n"
}

# Function to wait for user input
wait_for_user() {
    echo -e "\n${CYAN}Press Enter to continue...${NC}"
    read -r
}

# Function to check if command exists
command_exists() {
    command -v "$1" >/dev/null 2>&1
}

# Function to check requirements
check_requirements() {
    print_header "ğŸ” Checking Requirements"
    
    local missing_tools=()
    
    if ! command_exists docker; then
        missing_tools+=("docker")
    fi
    
    if ! command_exists docker-compose; then
        missing_tools+=("docker-compose")
    fi
    
    if ! command_exists python; then
        missing_tools+=("python")
    fi
    
    if ! command_exists pip; then
        missing_tools+=("pip")
    fi
    
    if [ ${#missing_tools[@]} -ne 0 ]; then
        print_error "Missing required tools: ${missing_tools[*]}"
        echo "Please install these tools before running the demo."
        exit 1
    fi
    
    print_success "All required tools are available!"
}

# Function to setup environment
setup_environment() {
    print_header "ğŸ› ï¸ Setting Up Environment"
    
    print_status "Creating virtual environment..."
    if [ ! -d "venv" ]; then
        python -m venv venv
    fi
    
    print_status "Activating virtual environment..."
    source venv/bin/activate
    
    print_status "Installing Python dependencies..."
    pip install -q -r requirements.txt
    
    print_status "Setting up MLflow..."
    make setup-mlflow > /dev/null 2>&1
    
    print_success "Environment setup completed!"
}

# Function to start services
start_services() {
    print_header "ğŸš€ Starting Services"
    
    print_status "Building Docker images..."
    make docker-build > /dev/null 2>&1
    
    print_status "Starting development environment..."
    make dev > /dev/null 2>&1
    
    print_status "Waiting for services to be ready..."
    sleep 10
    
    # Check if MLflow is running
    if curl -s http://localhost:5000 > /dev/null; then
        print_success "MLflow UI is running at http://localhost:5000"
    else
        print_warning "MLflow UI might still be starting up"
    fi
    
    print_success "Services started successfully!"
    
    echo -e "\n${CYAN}ğŸ”— Available Services:${NC}"
    echo "  â€¢ MLflow UI: http://localhost:5000"
    echo "  â€¢ Prometheus: http://localhost:9090"
    echo "  â€¢ Grafana: http://localhost:3000 (admin/admin)"
}

# Function to run training
run_training() {
    print_header "ğŸ¯ Running Model Training"
    
    print_status "Starting model training with MLflow tracking..."
    
    # Run training in background and capture output
    export MLFLOW_TRACKING_URI=http://localhost:5000
    
    # Use quick training for demo
    make train-quick > training.log 2>&1 &
    local train_pid=$!
    
    print_status "Training started (PID: $train_pid)"
    print_status "You can monitor progress at http://localhost:5000"
    
    # Wait for training to complete with progress indicator
    local spin='-\|/'
    local i=0
    while kill -0 $train_pid 2>/dev/null; do
        i=$(( (i+1) %4 ))
        printf "\r${YELLOW}Training in progress... ${spin:$i:1}${NC}"
        sleep 1
    done
    
    wait $train_pid
    local exit_code=$?
    
    if [ $exit_code -eq 0 ]; then
        print_success "Training completed successfully!"
        echo -e "\n${CYAN}Check the MLflow UI to see the experiment results:${NC}"
        echo "  http://localhost:5000"
    else
        print_error "Training failed with exit code $exit_code"
        echo "Check training.log for details"
    fi
}

# Function to demonstrate model comparison
compare_models() {
    print_header "ğŸ“Š Model Comparison & Promotion"
    
    print_status "Comparing model runs..."
    make compare-models
    
    wait_for_user
    
    print_status "Promoting best model to staging..."
    make promote-model
    
    print_success "Model promoted to staging!"
    echo -e "\n${CYAN}You can see the model in the MLflow Model Registry:${NC}"
    echo "  http://localhost:5000/#/models"
}

# Function to demonstrate model serving
demonstrate_serving() {
    print_header "ğŸŒ Model Serving Demo"
    
    print_status "Starting model serving..."
    
    # Start serving in background
    make serve-model > serving.log 2>&1 &
    local serve_pid=$!
    
    print_status "Waiting for model server to start..."
    sleep 15
    
    # Test health endpoint
    if curl -s http://localhost:8080/health > /dev/null; then
        print_success "Model server is healthy!"
        
        print_status "Testing model prediction..."
        
        # Make a sample prediction
        local response=$(curl -s -X POST http://localhost:8080/predict \
            -H "Content-Type: application/json" \
            -d '{"instances": [{"input": "def hello_world():\n    print(\"Hello, World!\")"}]}')
        
        if [ $? -eq 0 ]; then
            print_success "Prediction successful!"
            echo -e "\n${CYAN}Sample prediction response:${NC}"
            echo "$response" | python -m json.tool 2>/dev/null || echo "$response"
        else
            print_warning "Prediction test failed"
        fi
        
        # Stop serving
        kill $serve_pid 2>/dev/null || true
    else
        print_warning "Model server health check failed"
        kill $serve_pid 2>/dev/null || true
    fi
}

# Function to demonstrate CI/CD pipeline
demonstrate_cicd() {
    print_header "ğŸ”„ CI/CD Pipeline Demo"
    
    print_status "Running quality gates (linting, formatting, security)..."
    make format-check lint security > /dev/null 2>&1
    
    print_status "Running tests..."
    make test > /dev/null 2>&1
    
    print_success "All quality gates passed!"
    
    print_status "This is what happens in GitHub Actions:"
    echo "  1. âœ… Code formatting check"
    echo "  2. âœ… Linting and type checking"
    echo "  3. âœ… Security scanning"
    echo "  4. âœ… Unit tests with coverage"
    echo "  5. âœ… Integration tests"
    echo "  6. ğŸš€ Docker image build and push"
    echo "  7. ğŸŒ Deployment to AWS ECS"
}

# Function to show infrastructure
show_infrastructure() {
    print_header "â˜ï¸ Infrastructure Overview"
    
    print_status "Infrastructure components:"
    echo "  â€¢ AWS ECS Fargate - Container orchestration"
    echo "  â€¢ AWS RDS PostgreSQL - MLflow backend store"
    echo "  â€¢ AWS S3 - Model artifacts and data storage"
    echo "  â€¢ AWS ECR - Docker image registry"
    echo "  â€¢ AWS ALB - Load balancing and SSL termination"
    echo "  â€¢ Terraform - Infrastructure as Code"
    
    if [ -d "infra" ]; then
        print_status "Terraform configuration available in ./infra/"
        echo "  Run 'make infra-plan' to see deployment plan"
        echo "  Run 'make infra-apply' to deploy to AWS"
    fi
}

# Function to cleanup
cleanup() {
    print_header "ğŸ§¹ Cleanup"
    
    print_status "Stopping services..."
    make down > /dev/null 2>&1 || true
    
    print_status "Cleaning up artifacts..."
    rm -f training.log serving.log
    
    print_success "Cleanup completed!"
}

# Function to show final summary
show_summary() {
    print_header "ğŸ‰ Demo Summary"
    
    echo -e "${GREEN}âœ… Environment Setup${NC}"
    echo -e "${GREEN}âœ… Service Orchestration${NC}"
    echo -e "${GREEN}âœ… Model Training with MLflow${NC}"
    echo -e "${GREEN}âœ… Model Comparison & Promotion${NC}"
    echo -e "${GREEN}âœ… Model Serving${NC}"
    echo -e "${GREEN}âœ… CI/CD Pipeline${NC}"
    
    echo -e "\n${CYAN}ğŸ“š Next Steps:${NC}"
    echo "  â€¢ Explore the documentation: make docs-serve"
    echo "  â€¢ Deploy to AWS: make infra-apply"
    echo "  â€¢ Customize for your use case"
    echo "  â€¢ Add more models and experiments"
    
    echo -e "\n${PURPLE}ğŸ”— Useful Links:${NC}"
    echo "  â€¢ GitHub Repository: https://github.com/your-username/ml_ci_cd"
    echo "  â€¢ Documentation: https://your-username.github.io/ml_ci_cd"
    echo "  â€¢ MLflow: https://mlflow.org/"
    echo "  â€¢ AWS ECS: https://aws.amazon.com/ecs/"
}

# Main demo function
main() {
    echo -e "${PURPLE}"
    echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
    echo "â•‘                   ğŸš€ ML CI/CD Pipeline Demo                 â•‘"
    echo "â•‘                                                              â•‘"
    echo "â•‘  This demo will showcase a complete MLOps pipeline with:     â•‘"
    echo "â•‘  â€¢ MLflow experiment tracking                                â•‘"
    echo "â•‘  â€¢ Docker containerization                                   â•‘"
    echo "â•‘  â€¢ Model serving with FastAPI                               â•‘"
    echo "â•‘  â€¢ CI/CD with GitHub Actions                                â•‘"
    echo "â•‘  â€¢ AWS deployment with Terraform                            â•‘"
    echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo -e "${NC}\n"
    
    wait_for_user
    
    # Check if we're in the right directory
    if [ ! -f "README.md" ] || [ ! -f "Makefile" ]; then
        print_error "Please run this script from the project root directory"
        exit 1
    fi
    
    # Run demo steps
    check_requirements
    wait_for_user
    
    setup_environment
    wait_for_user
    
    start_services
    wait_for_user
    
    run_training
    wait_for_user
    
    compare_models
    wait_for_user
    
    demonstrate_serving
    wait_for_user
    
    demonstrate_cicd
    wait_for_user
    
    show_infrastructure
    wait_for_user
    
    cleanup
    
    show_summary
    
    print_success "Demo completed! ğŸ‰"
}

# Handle script interruption
trap cleanup EXIT

# Run main function
main "$@"
